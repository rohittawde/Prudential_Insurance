{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prudential insurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "raw_data = pd.read_csv(\"train.csv\")\n",
    "raw_data = raw_data[:1000]\n",
    "#len(raw_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleansing\n",
    "\n",
    "First of all we're currently restricting the number of rows to one thousand ottherwise it be messy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.16484375"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The isnull function returns a column wise boolean corresponding to the missing values\n",
    "missing_data = raw_data.isnull().sum()\n",
    "\n",
    "# Now we evaluate what percentage of the data is missing\n",
    "import numpy as np\n",
    "full_data = np.product(raw_data.shape)\n",
    "total_missing = missing_data.sum()\n",
    "(total_missing / full_data) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Product_Info_1</th>\n",
       "      <th>Product_Info_2</th>\n",
       "      <th>Product_Info_3</th>\n",
       "      <th>Product_Info_4</th>\n",
       "      <th>Product_Info_5</th>\n",
       "      <th>Product_Info_6</th>\n",
       "      <th>Product_Info_7</th>\n",
       "      <th>Ins_Age</th>\n",
       "      <th>Ht</th>\n",
       "      <th>...</th>\n",
       "      <th>Medical_Keyword_40</th>\n",
       "      <th>Medical_Keyword_41</th>\n",
       "      <th>Medical_Keyword_42</th>\n",
       "      <th>Medical_Keyword_43</th>\n",
       "      <th>Medical_Keyword_44</th>\n",
       "      <th>Medical_Keyword_45</th>\n",
       "      <th>Medical_Keyword_46</th>\n",
       "      <th>Medical_Keyword_47</th>\n",
       "      <th>Medical_Keyword_48</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Id, Product_Info_1, Product_Info_2, Product_Info_3, Product_Info_4, Product_Info_5, Product_Info_6, Product_Info_7, Ins_Age, Ht, Wt, BMI, Employment_Info_1, Employment_Info_2, Employment_Info_3, Employment_Info_4, Employment_Info_5, Employment_Info_6, InsuredInfo_1, InsuredInfo_2, InsuredInfo_3, InsuredInfo_4, InsuredInfo_5, InsuredInfo_6, InsuredInfo_7, Insurance_History_1, Insurance_History_2, Insurance_History_3, Insurance_History_4, Insurance_History_5, Insurance_History_7, Insurance_History_8, Insurance_History_9, Family_Hist_1, Family_Hist_2, Family_Hist_3, Family_Hist_4, Family_Hist_5, Medical_History_1, Medical_History_2, Medical_History_3, Medical_History_4, Medical_History_5, Medical_History_6, Medical_History_7, Medical_History_8, Medical_History_9, Medical_History_10, Medical_History_11, Medical_History_12, Medical_History_13, Medical_History_14, Medical_History_15, Medical_History_16, Medical_History_17, Medical_History_18, Medical_History_19, Medical_History_20, Medical_History_21, Medical_History_22, Medical_History_23, Medical_History_24, Medical_History_25, Medical_History_26, Medical_History_27, Medical_History_28, Medical_History_29, Medical_History_30, Medical_History_31, Medical_History_32, Medical_History_33, Medical_History_34, Medical_History_35, Medical_History_36, Medical_History_37, Medical_History_38, Medical_History_39, Medical_History_40, Medical_History_41, Medical_Keyword_1, Medical_Keyword_2, Medical_Keyword_3, Medical_Keyword_4, Medical_Keyword_5, Medical_Keyword_6, Medical_Keyword_7, Medical_Keyword_8, Medical_Keyword_9, Medical_Keyword_10, Medical_Keyword_11, Medical_Keyword_12, Medical_Keyword_13, Medical_Keyword_14, Medical_Keyword_15, Medical_Keyword_16, Medical_Keyword_17, Medical_Keyword_18, Medical_Keyword_19, Medical_Keyword_20, Medical_Keyword_21, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 128 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Product_Info_1</th>\n",
       "      <th>Product_Info_2</th>\n",
       "      <th>Product_Info_3</th>\n",
       "      <th>Product_Info_4</th>\n",
       "      <th>Product_Info_5</th>\n",
       "      <th>Product_Info_6</th>\n",
       "      <th>Product_Info_7</th>\n",
       "      <th>Ins_Age</th>\n",
       "      <th>Ht</th>\n",
       "      <th>...</th>\n",
       "      <th>Medical_Keyword_40</th>\n",
       "      <th>Medical_Keyword_41</th>\n",
       "      <th>Medical_Keyword_42</th>\n",
       "      <th>Medical_Keyword_43</th>\n",
       "      <th>Medical_Keyword_44</th>\n",
       "      <th>Medical_Keyword_45</th>\n",
       "      <th>Medical_Keyword_46</th>\n",
       "      <th>Medical_Keyword_47</th>\n",
       "      <th>Medical_Keyword_48</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>D3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.641791</td>\n",
       "      <td>0.581818</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>A1</td>\n",
       "      <td>26</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.059701</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>E1</td>\n",
       "      <td>26</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>0.745455</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>D4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.164179</td>\n",
       "      <td>0.672727</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>D2</td>\n",
       "      <td>26</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.417910</td>\n",
       "      <td>0.654545</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 115 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Product_Info_1 Product_Info_2  Product_Info_3  Product_Info_4  \\\n",
       "0   2               1             D3              10        0.076923   \n",
       "1   5               1             A1              26        0.076923   \n",
       "2   6               1             E1              26        0.076923   \n",
       "3   7               1             D4              10        0.487179   \n",
       "4   8               1             D2              26        0.230769   \n",
       "\n",
       "   Product_Info_5  Product_Info_6  Product_Info_7   Ins_Age        Ht  \\\n",
       "0               2               1               1  0.641791  0.581818   \n",
       "1               2               3               1  0.059701  0.600000   \n",
       "2               2               3               1  0.029851  0.745455   \n",
       "3               2               3               1  0.164179  0.672727   \n",
       "4               2               3               1  0.417910  0.654545   \n",
       "\n",
       "     ...     Medical_Keyword_40  Medical_Keyword_41  Medical_Keyword_42  \\\n",
       "0    ...                      0                   0                   0   \n",
       "1    ...                      0                   0                   0   \n",
       "2    ...                      0                   0                   0   \n",
       "3    ...                      0                   0                   0   \n",
       "4    ...                      0                   0                   0   \n",
       "\n",
       "   Medical_Keyword_43  Medical_Keyword_44  Medical_Keyword_45  \\\n",
       "0                   0                   0                   0   \n",
       "1                   0                   0                   0   \n",
       "2                   0                   0                   0   \n",
       "3                   0                   0                   0   \n",
       "4                   0                   0                   0   \n",
       "\n",
       "   Medical_Keyword_46  Medical_Keyword_47  Medical_Keyword_48  Response  \n",
       "0                   0                   0                   0         8  \n",
       "1                   0                   0                   0         4  \n",
       "2                   0                   0                   0         8  \n",
       "3                   0                   0                   0         8  \n",
       "4                   0                   0                   0         8  \n",
       "\n",
       "[5 rows x 115 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_with_na_dropped = raw_data.dropna(axis = 1)\n",
    "columns_with_na_dropped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns within orignal data 128 \n",
      "\n",
      "Columns with na's dropped: 115\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns within orignal data %d \\n\" %raw_data.shape[1])\n",
    "print(\"Columns with na's dropped: %d\" % columns_with_na_dropped.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def missing(dataframe):\n",
    "    miss = dataframe.isnull().sum()\n",
    "    return miss.sum()\n",
    "\n",
    "# Checking how many NA values still remain\n",
    "missing(columns_with_na_dropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Family_Hist_1</th>\n",
       "      <th>Family_Hist_2</th>\n",
       "      <th>Family_Hist_3</th>\n",
       "      <th>Family_Hist_4</th>\n",
       "      <th>Family_Hist_5</th>\n",
       "      <th>Medical_History_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.598039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.526786</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.188406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.084507</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.225352</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.420290</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.352113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.463768</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.408451</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Family_Hist_1  Family_Hist_2  Family_Hist_3  Family_Hist_4  Family_Hist_5  \\\n",
       "0              2            NaN       0.598039            NaN       0.526786   \n",
       "1              2       0.188406            NaN       0.084507            NaN   \n",
       "2              3       0.304348            NaN       0.225352            NaN   \n",
       "3              3       0.420290            NaN       0.352113            NaN   \n",
       "4              2       0.463768            NaN       0.408451            NaN   \n",
       "\n",
       "   Medical_History_1  \n",
       "0                4.0  \n",
       "1                5.0  \n",
       "2               10.0  \n",
       "3                0.0  \n",
       "4                NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_raw_data = raw_data.loc[:, 'Family_Hist_1':'Medical_History_1'].head()\n",
    "subset_raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Family_Hist_1</th>\n",
       "      <th>Family_Hist_2</th>\n",
       "      <th>Family_Hist_3</th>\n",
       "      <th>Family_Hist_4</th>\n",
       "      <th>Family_Hist_5</th>\n",
       "      <th>Medical_History_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.598039</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.526786</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.188406</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.084507</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.225352</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.420290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.352113</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.463768</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.408451</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Family_Hist_1  Family_Hist_2  Family_Hist_3  Family_Hist_4  Family_Hist_5  \\\n",
       "0              2       0.000000       0.598039       0.000000       0.526786   \n",
       "1              2       0.188406       0.000000       0.084507       0.000000   \n",
       "2              3       0.304348       0.000000       0.225352       0.000000   \n",
       "3              3       0.420290       0.000000       0.352113       0.000000   \n",
       "4              2       0.463768       0.000000       0.408451       0.000000   \n",
       "\n",
       "   Medical_History_1  \n",
       "0                4.0  \n",
       "1                5.0  \n",
       "2               10.0  \n",
       "3                0.0  \n",
       "4                0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_raw_data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Employment_Info_1', 'Employment_Info_4', 'Employment_Info_6',\n",
       "       'Insurance_History_5', 'Family_Hist_2', 'Family_Hist_3',\n",
       "       'Family_Hist_4', 'Family_Hist_5', 'Medical_History_1',\n",
       "       'Medical_History_10', 'Medical_History_15', 'Medical_History_24',\n",
       "       'Medical_History_32'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking which columns indeed have missing entries in order to check whether to drop or impute\n",
    "raw_data.columns[raw_data.isnull().any()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what we are going to do with our missing values:\n",
    "\n",
    "- Error 404 : These are categorical  variables. The probable reason that these entries are missing is that they might not exist. In such a scenario where a categorical variable is missing, assigning it to any other existing category can have malignent effect on our dataset. It would be prudent `pun intended` to assign it to a new category corresponding to *not available*.\n",
    "\n",
    "\n",
    "- Employment_Info_1/4/6, Insurance_History_5, Family_Hist_2/3/4/5 : These are continuous variables. Without knowing the details of what these terms correspond to it is hard to pin down the exact causation corresponding to their absence. It is important to note that the rows in which thene missing cells exist are not sparse we cannot drop them. What we can do instead is to impute the missing variables with their mean, since they are continuous.\n",
    "\n",
    "\n",
    "- Medical_History_1/10/15/24/32 : These are discrete variables. By observation the columns in the medical history seem to be very sparse however they have substantial range. These could bu further quantified and evaluated for two scenarios depending on it's sparsity and range, either we drop the columns or fill it with the mean value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def averaging_na(column):\n",
    "    avg = raw_data[column].mean()\n",
    "    raw_data[column] = raw_data[column].fillna(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# averaging_na('Employment_Info_6')\n",
    "# raw_data['Employment_Info_6'].isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values in Employment_Info_1? \n",
      "False\n",
      "Null values in Employment_Info_4? \n",
      "False\n",
      "Null values in Employment_Info_6? \n",
      "False\n",
      "Null values in Insurance_History_5? \n",
      "False\n",
      "Null values in Family_Hist_2? \n",
      "False\n",
      "Null values in Family_Hist_3? \n",
      "False\n",
      "Null values in Family_Hist_4? \n",
      "False\n",
      "Null values in Family_Hist_5? \n",
      "False\n"
     ]
    }
   ],
   "source": [
    "continuous = ['Employment_Info_1', 'Employment_Info_4', 'Employment_Info_6', 'Insurance_History_5', 'Family_Hist_2', 'Family_Hist_3', 'Family_Hist_4', 'Family_Hist_5']\n",
    "\n",
    "for c in continuous:\n",
    "    averaging_na(c)\n",
    "    \n",
    "# Checking if there are any null values in our continuous features\n",
    "for c in continuous:\n",
    "    print(\"Null values in \" + c + \"? \")\n",
    "    print(raw_data[c].isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of missing values in Medical_History_1 are: 139 and the range is 153.0\n",
      "The total number of missing values in Medical_History_10 are: 993 and the range is 239.0\n",
      "The total number of missing values in Medical_History_15 are: 757 and the range is 240.0\n",
      "The total number of missing values in Medical_History_24 are: 931 and the range is 240.0\n",
      "The total number of missing values in Medical_History_32 are: 981 and the range is 157.0\n"
     ]
    }
   ],
   "source": [
    "# Now we quantify the number of null values and the range of the columns with missing discrete values\n",
    "discrete = ['Medical_History_1','Medical_History_10', 'Medical_History_15', 'Medical_History_24', 'Medical_History_32']\n",
    "\n",
    "for d in discrete:\n",
    "    range_ = raw_data[d].max() - raw_data[d].min()\n",
    "    print(\"The total number of missing values in \" + d + \" are: {0} and the range is {1}\" .format(raw_data[d].isnull().sum(), range_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the Medical_History_10/24/32 aren't contributing much because of the sparsity so we cna drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refined_data = raw_data.drop(['Medical_History_10', 'Medical_History_24', 'Medical_History_32'], axis = 1)\n",
    "raw_data['Medical_History_1'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "sns.countplot(raw_data['Medical_History_1'])\n",
    "plt.xticks(fontsize = 8, rotation = 90)\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "sns.countplot(raw_data['Medical_History_15'])\n",
    "plt.xticks(fontsize = 8, rotation = 90)\n",
    "\n",
    "plt.show()\n",
    "#refined_data['Medical_History_15'].value_counts()\n",
    "\n",
    "# Replacing missing values with the median\n",
    "refined_data['Medical_History_1'] = refined_data['Medical_History_1'].fillna(4)\n",
    "\n",
    "# Replacing the entire bag of missing values in the series with one value will disrupt the distribution hence deciding to drop it\n",
    "refined_data = refined_data.drop(['Medical_History_15'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a clean dataset devoid of any missing values so we can start the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Product_Info_2'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for object types\n",
    "raw_data.select_dtypes(include=['O']).columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "number = LabelEncoder()\n",
    "Product_Info_2 = dict(zip(refined_data['Product_Info_2'], number.fit_transform(refined_data['Product_Info_2'].astype('str'))))\n",
    "refined_data['Product_Info_2'] = number.fit_transform(refined_data['Product_Info_2'].astype('str'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = refined_data.Response\n",
    "X = refined_data.drop(columns = ['Response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit(X).transform(X)\n",
    "#print(\"The maximum value per feature is :\\n{} \".format(X.max(axis = 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rohit Tawde\\anacondba\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\Rohit Tawde\\anacondba\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=1, n_neighbors=15, p=2,\n",
       "            weights='uniform'),\n",
       " {'n_neighbors': 15},\n",
       " 0.36,\n",
       " [mean: 0.32000, std: 0.04623, params: {'n_neighbors': 5},\n",
       "  mean: 0.33600, std: 0.03506, params: {'n_neighbors': 10},\n",
       "  mean: 0.36000, std: 0.02576, params: {'n_neighbors': 15},\n",
       "  mean: 0.35067, std: 0.02857, params: {'n_neighbors': 20},\n",
       "  mean: 0.33867, std: 0.01681, params: {'n_neighbors': 50},\n",
       "  mean: 0.32533, std: 0.01020, params: {'n_neighbors': 100},\n",
       "  mean: 0.32000, std: 0.00379, params: {'n_neighbors': 200},\n",
       "  mean: 0.32000, std: 0.00379, params: {'n_neighbors': 300}])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "knn = KNeighborsClassifier()\n",
    "parameters = {\"n_neighbors\" : [5, 10, 15, 20, 50, 100, 200, 300]}\n",
    "fitmodel = GridSearchCV(knn, param_grid = parameters, cv = 5, scoring = \"accuracy\")\n",
    "fitmodel.fit(X_train, Y_train)\n",
    "fitmodel.best_estimator_, fitmodel.best_params_, fitmodel.best_score_, fitmodel.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8    240\n",
      "6    137\n",
      "7    104\n",
      "2    100\n",
      "1     81\n",
      "5     62\n",
      "4     21\n",
      "3      5\n",
      "Name: Response, dtype: int64\n",
      "750\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(Y_train)\n",
    "print(Y_train.value_counts())\n",
    "print(len(Y_train))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy so to say:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Baseline accuracy so to say:\")\n",
    "accuracy_score(np.ones(len(Y_test)) * 8, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After tuning our hyperparameter we observe that K = 15 gives us a better accuracy which is an improvement over our baseline. We can however this seems to be the maximum accuracy which KNN can offer. In an attempt to improve on this score we try other algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "           intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "           n_jobs=1, penalty='l2', random_state=53, solver='lbfgs',\n",
       "           tol=0.0001, verbose=0, warm_start=False),\n",
       " {'C': 0.01},\n",
       " 0.4093333333333333,\n",
       " [mean: 0.40933, std: 0.03363, params: {'C': 0.01},\n",
       "  mean: 0.39600, std: 0.02913, params: {'C': 0.05},\n",
       "  mean: 0.38800, std: 0.03349, params: {'C': 0.1},\n",
       "  mean: 0.37733, std: 0.02335, params: {'C': 0.3},\n",
       "  mean: 0.37333, std: 0.02610, params: {'C': 0.5},\n",
       "  mean: 0.37333, std: 0.03028, params: {'C': 0.7},\n",
       "  mean: 0.36800, std: 0.02891, params: {'C': 0.9},\n",
       "  mean: 0.36800, std: 0.03028, params: {'C': 1}])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(multi_class = 'multinomial', solver = 'lbfgs', random_state = 53)\n",
    "#lr.fit(X_train, Y_train)\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "parameters = {\"C\": [0.01, 0.05, 0.1, 0.3, 0.5, 0.7, 0.9, 1]}\n",
    "fitmodel_lr = GridSearchCV(lr, param_grid = parameters, cv = 5)\n",
    "fitmodel_lr.fit(X_train, Y_train)\n",
    "fitmodel_lr.best_estimator_, fitmodel_lr.best_params_, fitmodel_lr.best_score_, fitmodel_lr.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.424"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_2 = LogisticRegression(C = 0.01, random_state = 53)\n",
    "lr_2.fit(X_train, Y_train)\n",
    "predict_lr = lr_2.predict(X_test)\n",
    "accuracy_score(predict_lr, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy aspects considered Logistic Regression provides a slightly better result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to a large number of features I tried implementing a greedy feature elimination algorithm, trying to see if lesse number of features provide a better representation by cutting through the unnecessary noise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_plot = []\n",
    "from sklearn.feature_selection import RFE\n",
    "lr = LogisticRegression(C = 0.01, random_state = 53)\n",
    "\n",
    "for i in range(2,52):    \n",
    "    selector = RFE(lr, i, step = 1)\n",
    "    selector = selector.fit(X_train, Y_train)\n",
    "    n_pred = selector.predict(X_test)\n",
    "    pl = accuracy_score(n_pred, Y_test)\n",
    "    array_plot.append(pl)\n",
    "#selector.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(array_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.464"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_plot[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
